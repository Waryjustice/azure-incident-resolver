from flask import Flask, render_template, jsonify
from flask_socketio import SocketIO, emit
from datetime import datetime
import os
import sys
import json
from dotenv import load_dotenv
from collections import deque
from threading import Thread
import time

load_dotenv(os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', '.env'))

# --- Real AI client (sync, safe to use in threads) ---
sys.path.insert(0, os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', 'src'))
_AI_CLIENT = None
_AI_MODEL = os.getenv("GITHUB_MODEL_NAME", "gpt-4o-mini")
try:
    from azure.ai.inference import ChatCompletionsClient
    from azure.ai.inference.models import SystemMessage, UserMessage
    from azure.core.credentials import AzureKeyCredential
    _github_token = os.getenv("GITHUB_TOKEN", "")
    if _github_token:
        _AI_CLIENT = ChatCompletionsClient(
            endpoint="https://models.inference.ai.azure.com",
            credential=AzureKeyCredential(_github_token),
        )
        print(f"[Dashboard] ‚úÖ GitHub Models AI client ready ({_AI_MODEL})")
    else:
        print("[Dashboard] ‚ö†Ô∏è  GITHUB_TOKEN not set ‚Äî AI unavailable")
except Exception as _e:
    print(f"[Dashboard] ‚ö†Ô∏è  AI client init failed: {_e}")

# --- Real Azure SDK imports (for resolution) ---
try:
    from agents.resolution.agent import ResolutionAgent as _ResolutionAgent
    _REAL_AGENTS = True
    print("[Dashboard] ‚úÖ Resolution agent imported successfully")
except Exception as _e:
    _REAL_AGENTS = False
    print(f"[Dashboard] ‚ö†Ô∏è  Resolution agent unavailable: {_e} ‚Äî using simulation")

# Incident shape each scenario maps to for the real diagnosis agent
_SCENARIO_INCIDENTS = {
    'database-spike':    {'resource': {'type': 'Database',    'name': 'incident-demo-db'},          'anomalies': [{'metric': 'CONNECTION_COUNT',      'value': 847,  'threshold': 100, 'severity': 'critical'}]},
    'memory-leak':       {'resource': {'type': 'App Service', 'name': 'incident-demo-app-ss2026'},   'anomalies': [{'metric': 'MEMORY_USAGE',          'value': 95,   'threshold': 80,  'severity': 'critical'}]},
    'rate-limit':        {'resource': {'type': 'API Gateway', 'name': 'payment-api-gateway'},        'anomalies': [{'metric': 'RATE_LIMIT_ERRORS',     'value': 420,  'threshold': 100, 'severity': 'high'}]},
    'failed-deployment': {'resource': {'type': 'App Service', 'name': 'incident-demo-app-ss2026'},   'anomalies': [{'metric': 'DEPLOYMENT_ERROR_RATE', 'value': 150,  'threshold': 10,  'severity': 'critical'}]},
    'disk-space':        {'resource': {'type': 'VM',          'name': 'prod-disk-001'},              'anomalies': [{'metric': 'DISK_USAGE',            'value': 95,   'threshold': 80,  'severity': 'critical'}]},
    'ssl-expiring':      {'resource': {'type': 'App Service', 'name': 'incident-demo-app-ss2026'},   'anomalies': [{'metric': 'CERT_EXPIRY_DAYS',      'value': 5,    'threshold': 30,  'severity': 'high'}]},
    'cpu-spike':         {'resource': {'type': 'AKS',         'name': 'aks-prod-api'},               'anomalies': [{'metric': 'CPU_USAGE',             'value': 98,   'threshold': 80,  'severity': 'critical'}]},
    'database-deadlock': {'resource': {'type': 'Database',    'name': 'db-prod-payment'},            'anomalies': [{'metric': 'DEADLOCK_COUNT',        'value': 42,   'threshold': 0,   'severity': 'critical'}]},
    'cache-down':        {'resource': {'type': 'Redis Cache', 'name': 'redis-prod-01'},              'anomalies': [{'metric': 'CACHE_MISS_RATE',       'value': 100,  'threshold': 20,  'severity': 'critical'}]},
    'slow-query':        {'resource': {'type': 'Database',    'name': 'db-prod-analytics'},          'anomalies': [{'metric': 'QUERY_DURATION',        'value': 35000,'threshold': 800, 'severity': 'critical'}]},
    'new-feature-bug':   {'resource': {'type': 'App Service', 'name': 'user-dashboard-v2'},          'anomalies': [{'metric': 'ERROR_RATE',            'value': 42,   'threshold': 5,   'severity': 'critical'}]},
}

app = Flask(__name__, template_folder='templates')
app.config['SECRET_KEY'] = os.getenv('FLASK_SECRET_KEY', 'dev-secret-key-change-in-production')
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# In-memory storage for incidents and metrics
incidents = deque(maxlen=100)
logs = deque(maxlen=500)
agent_status = {
    'detection': {'status': 'idle', 'last_check': None, 'incidents_detected': 0},
    'diagnosis': {'status': 'idle', 'last_check': None, 'analyses_completed': 0},
    'resolution': {'status': 'idle', 'last_check': None, 'issues_resolved': 0},
    'communication': {'status': 'idle', 'last_check': None, 'notifications_sent': 0}
}
metrics = {
    'avg_mttr': 0,
    'incidents_this_week': 0,
    'resolution_rate': 85,
    'false_positive_rate': 5
}
_resolved_count = 0  # track resolved count for proper MTTR averaging


@app.route('/')
def index():
    """Render the dashboard home page."""
    return render_template('index.html')


@app.route('/api/incidents')
def get_incidents():
    """Get all incidents."""
    return jsonify(list(incidents))


@app.route('/api/agents/status')
def get_agent_status():
    """Get current status of all agents."""
    return jsonify(agent_status)


@app.route('/api/metrics')
def get_metrics():
    """Get system metrics."""
    return jsonify(metrics)


@app.route('/api/logs')
def get_logs():
    """Get all logs."""
    return jsonify(list(logs))


def add_log(agent_name, message):
    """Add a log entry and broadcast to clients."""
    log_entry = {
        'timestamp': datetime.utcnow().isoformat(),
        'agent': agent_name,
        'message': message
    }
    logs.append(log_entry)
    socketio.emit('new_log', log_entry)


@socketio.on('connect')
def handle_connect():
    """Handle client connection."""
    emit('connection_response', {'data': 'Connected to dashboard'})
    emit_current_state()


def emit_current_state():
    """Emit current state to all connected clients."""
    socketio.emit('agent_status', agent_status)
    socketio.emit('incidents_update', list(incidents))
    socketio.emit('metrics_update', metrics)
    socketio.emit('logs_update', list(logs))


@socketio.on('request_status')
def handle_status_request():
    """Handle status request from client."""
    emit_current_state()


def add_incident(incident_data):
    """Add a new incident to the dashboard."""
    incident = {
        'id': len(incidents) + 1,
        'timestamp': datetime.utcnow().isoformat(),
        'title': incident_data.get('title', 'Unknown Incident'),
        'severity': incident_data.get('severity', 'medium'),
        'status': incident_data.get('status', 'detecting'),
        'description': incident_data.get('description', ''),
        'affected_resource': incident_data.get('affected_resource', ''),
        'mttr': 0,
        'timeline': [
            {
                'timestamp': datetime.utcnow().isoformat(),
                'agent': 'detection',
                'action': 'Incident detected',
                'icon': 'üîç'
            }
        ]
    }
    incidents.append(incident)
    socketio.emit('new_incident', incident)
    return incident


def update_agent_status(agent_name, status, data=None):
    """Update agent status and broadcast to clients."""
    if agent_name in agent_status:
        agent_status[agent_name]['status'] = status
        agent_status[agent_name]['last_check'] = datetime.utcnow().isoformat()
        if data:
            agent_status[agent_name].update(data)
        socketio.emit('agent_status_update', {agent_name: agent_status[agent_name]})


def update_incident_status(incident_id, status, mttr=None, action=None):
    """Update incident status and add timeline entry."""
    agent_map = {
        'diagnosing': ('diagnosis', 'üß†', 'Running root cause analysis'),
        'resolving': ('resolution', 'üîß', 'Executing automated fixes'),
        'communicating': ('communication', 'üí¨', 'Sending notifications and post-mortem'),
        'resolved': ('communication', '‚úÖ', 'Incident resolved')
    }
    
    for incident in incidents:
        if incident['id'] == incident_id:
            incident['status'] = status
            if mttr is not None:
                incident['mttr'] = mttr
            
            if status in agent_map:
                agent_name, icon, default_action = agent_map[status]
                incident['timeline'].append({
                    'timestamp': datetime.utcnow().isoformat(),
                    'agent': agent_name,
                    'action': action or default_action,
                    'icon': icon
                })
            
            socketio.emit('incident_update', incident)
            break


def update_metrics(new_metrics):
    """Update system metrics."""
    metrics.update(new_metrics)
    socketio.emit('metrics_update', metrics)


def create_demo_scenarios():
    """Define available demo scenarios."""
    return {
        'database-spike': {
            'title': 'Database Connection Pool Exhausted',
            'severity': 'critical',
            'description': 'Connection pool at 95% capacity, API requests timing out',
            'affected_resource': 'prod-db-01',
            'duration': 8,       # wall-clock simulation seconds
            'mttr_seconds': 180  # realistic MTTR to display (3 min)
        },
        'memory-leak': {
            'title': 'Memory Leak Detected',
            'severity': 'high',
            'description': 'Service memory usage at 95%, OOM imminent',
            'affected_resource': 'prod-api-service-03',
            'duration': 6,
            'mttr_seconds': 120  # 2 min
        },
        'rate-limit': {
            'title': 'API Rate Limit Breach',
            'severity': 'high',
            'description': 'Third-party API throttling, 42% error rate',
            'affected_resource': 'payment-api-gateway',
            'duration': 10,
            'mttr_seconds': 480  # 8 min
        },
        'failed-deployment': {
            'title': 'Failed Deployment v2.4.1',
            'severity': 'critical',
            'description': 'New deployment causes 15% error rate, 25K failed requests',
            'affected_resource': 'api-prod-cluster',
            'duration': 8,
            'mttr_seconds': 240  # 4 min
        },
        'disk-space': {
            'title': 'Disk Space Critical',
            'severity': 'critical',
            'description': 'Disk 95% full, logs consuming 450GB, only 2GB free',
            'affected_resource': 'prod-disk-001',
            'duration': 7,
            'mttr_seconds': 180  # 3 min
        },
        'ssl-expiring': {
            'title': 'SSL Certificate Expiring',
            'severity': 'high',
            'description': 'SSL cert expires in 5 days for api.prod.azureincidents.com',
            'affected_resource': 'cert-prod-01',
            'duration': 9,
            'mttr_seconds': 300  # 5 min
        },
        'cpu-spike': {
            'title': 'Sustained High CPU Load',
            'severity': 'critical',
            'description': 'CPU 98%, response times 8500ms, 15K users affected',
            'affected_resource': 'aks-prod-api',
            'duration': 8,
            'mttr_seconds': 240  # 4 min
        },
        'database-deadlock': {
            'title': 'Database Deadlock',
            'severity': 'critical',
            'description': '42 transactions deadlocked, payment processing halted',
            'affected_resource': 'db-prod-payment',
            'duration': 5,
            'mttr_seconds': 120  # 2 min
        },
        'cache-down': {
            'title': 'Redis Cache Down',
            'severity': 'critical',
            'description': '100% cache miss, API latency 3500ms, 12K users affected',
            'affected_resource': 'redis-prod-01',
            'duration': 7,
            'mttr_seconds': 180  # 3 min
        },
        'slow-query': {
            'title': 'Slow Database Query',
            'severity': 'critical',
            'description': 'Query 35s (normally 0.8s), missing index on 50M row table',
            'affected_resource': 'db-prod-analytics',
            'duration': 9,
            'mttr_seconds': 240  # 4 min
        },
        'new-feature-bug': {
            'title': 'New Feature Bug - No Rollback Available',
            'severity': 'critical',
            'description': 'User Dashboard v2.0 NullPointerException, 25K failed requests, no rollback',
            'affected_resource': 'user-dashboard-v2',
            'duration': 10,
            'mttr_seconds': 300  # 5 min
        }
    }


@app.route('/api/demo/scenarios')
def get_demo_scenarios():
    """Get available demo scenarios."""
    scenarios = create_demo_scenarios()
    return jsonify({key: {k: v for k, v in value.items() if k != 'duration'} 
                   for key, value in scenarios.items()})


@app.route('/api/demo/trigger-incident/<scenario_type>', methods=['POST'])
def trigger_demo_incident(scenario_type):
    """Trigger a demo incident for testing."""
    try:
        scenarios = create_demo_scenarios()
        
        if scenario_type not in scenarios:
            return jsonify({'error': f'Invalid scenario type: {scenario_type}. Valid types: {list(scenarios.keys())}'}), 400
        
        scenario = scenarios[scenario_type]
        incident = add_incident({
            'title': scenario['title'],
            'severity': scenario['severity'],
            'description': scenario['description'],
            'affected_resource': scenario['affected_resource']
        })
        
        def simulate_workflow():
            global _resolved_count
            try:
                duration = scenario['duration']

                # Per-scenario detection/diagnosis/resolution messages
                scenario_details = {
                    'database-spike': {
                        'detection': [
                            'Database connection pool at 98% ‚Äî 847 active connections (limit: 100)',
                            'API latency spiking to 8500ms, request queue backing up',
                        ],
                        'diagnosis': [
                            'Root cause: Unclosed connections in request handler causing pool exhaustion',
                            'Evidence: 412 leaked connections over last 15 minutes, 0 connections being released',
                        ],
                        'resolution': [
                            'Scaling database from S1 ‚Üí S3 tier via Azure SQL Management SDK...',
                            'Generating connection pool fix via GitHub Copilot Agent Mode...',
                            '‚úì Database scaled: S1 ‚Üí S3 (300% capacity increase)',
                            '‚úì PR created: Connection pool with proper cleanup handlers ‚Äî pull/1247',
                        ],
                        'post_mortem': 'Root cause: missing connection.close() in exception paths. Fix: context manager pattern applied.',
                    },
                    'memory-leak': {
                        'detection': [
                            'Service memory at 95% (7.6GB / 8GB), growing 200MB/min',
                            'OOM kill predicted in ~2 minutes on prod-api-service-03',
                        ],
                        'diagnosis': [
                            'Root cause: Unbounded in-memory session cache missing TTL and maxsize',
                            'Evidence: SessionManager cache contains 2.1M entries, never evicted',
                        ],
                        'resolution': [
                            'Restarting App Service to recover memory via Azure Web Management SDK...',
                            'Generating LRU cache fix via GitHub Copilot Agent Mode...',
                            '‚úì Service restarted, memory restored to 22% (1.8GB)',
                            '‚úì PR created: LRU cache with TTL=3600s and maxsize=10000 ‚Äî pull/1251',
                        ],
                        'post_mortem': 'Root cause: session cache unbounded growth. Fix: cachetools LRU with eviction policy.',
                    },
                    'rate-limit': {
                        'detection': [
                            'Payment API returning HTTP 429 ‚Äî 42% of requests failing',
                            'Third-party rate limit: 1000 req/min quota, current burst 3200 req/min',
                        ],
                        'diagnosis': [
                            'Root cause: No rate limiter or backoff logic on outgoing payment API calls',
                            'Evidence: 12,400 failed payment requests in last 10 minutes',
                        ],
                        'resolution': [
                            'Enabling circuit breaker via Azure App Service config SDK...',
                            'Generating exponential backoff retry logic via GitHub Copilot Agent Mode...',
                            '‚úì Circuit breaker enabled ‚Äî non-critical requests queued',
                            '‚úì PR created: Exponential backoff with jitter, max 3 retries ‚Äî pull/1309',
                        ],
                        'post_mortem': 'Root cause: missing backoff on 3rd-party API. Fix: tenacity retry with exponential backoff.',
                    },
                    'failed-deployment': {
                        'detection': [
                            'Deployment v2.4.1 causing 15% error rate ‚Äî 25,000 failed requests',
                            'HTTP 500 errors spiked immediately after deploy at 14:32 UTC',
                        ],
                        'diagnosis': [
                            'Root cause: Breaking database schema change in v2.4.1 ‚Äî column renamed without migration',
                            'Evidence: "column user_name does not exist" in 100% of error stack traces',
                        ],
                        'resolution': [
                            'Initiating slot swap rollback to v2.4.0 via Azure Web Management SDK...',
                            'Generating migration fix via GitHub Copilot Agent Mode...',
                            '‚úì Rolled back to v2.4.0 ‚Äî error rate restored to 0.1%',
                            '‚úì PR created: Backwards-compatible migration with column alias ‚Äî pull/1388',
                        ],
                        'post_mortem': 'Root cause: breaking schema change deployed without backward compatibility. Fix: dual-write migration pattern.',
                    },
                    'disk-space': {
                        'detection': [
                            'Disk usage at 95% on prod-disk-001 ‚Äî only 2GB remaining',
                            'Log files consuming 450GB ‚Äî rotation policy not configured',
                        ],
                        'diagnosis': [
                            'Root cause: Application logs never rotated, accumulating since last deploy',
                            'Evidence: /var/log/app/access.log is 312GB (single file, uncompressed)',
                        ],
                        'resolution': [
                            'Purging log files older than 7 days via Azure CLI...',
                            'Generating logrotate config via GitHub Copilot Agent Mode...',
                            '‚úì Purged 430GB ‚Äî disk usage restored to 18%',
                            '‚úì PR created: logrotate with daily rotation, 7-day retention, gzip ‚Äî pull/1412',
                        ],
                        'post_mortem': 'Root cause: no log rotation policy. Fix: logrotate config applied, alerting at 80% disk.',
                    },
                    'ssl-expiring': {
                        'detection': [
                            'SSL certificate expires in 5 days for api.prod.azureincidents.com',
                            'Certificate issued 2025-02-23, expires 2026-02-28 ‚Äî 5 days remaining',
                        ],
                        'diagnosis': [
                            'Root cause: Certificate auto-renewal not configured ‚Äî manual renewal was missed',
                            'Evidence: ACME renewal cron job disabled after server migration in December',
                        ],
                        'resolution': [
                            'Triggering emergency certificate renewal via Azure Key Vault API...',
                            'Generating auto-renewal automation via GitHub Copilot Agent Mode...',
                            '‚úì New certificate issued ‚Äî valid for 90 days',
                            '‚úì PR created: ACME auto-renewal script with 30-day pre-expiry check ‚Äî pull/1455',
                        ],
                        'post_mortem': 'Root cause: renewal automation disabled after migration. Fix: ACME cron restored with monitoring.',
                    },
                    'cpu-spike': {
                        'detection': [
                            'CPU at 98% on aks-prod-api ‚Äî response times 8500ms, 15K users affected',
                            'Pod CPU throttling at 100% for 8 of 8 running pods',
                        ],
                        'diagnosis': [
                            'Root cause: N+1 query pattern in /api/users endpoint ‚Äî 1 query per user row',
                            'Evidence: 847 sequential DB queries per API request traced via App Insights',
                        ],
                        'resolution': [
                            'Scaling AKS pods from 3 ‚Üí 9 via Azure Container SDK...',
                            'Generating optimized batch query via GitHub Copilot Agent Mode...',
                            '‚úì Pods scaled to 9 ‚Äî CPU dropped to 34%, latency restored to 180ms',
                            '‚úì PR created: Batch query with JOIN replaces N+1 pattern ‚Äî pull/1489',
                        ],
                        'post_mortem': 'Root cause: N+1 query in users endpoint. Fix: single batched JOIN query, response time -97%.',
                    },
                    'database-deadlock': {
                        'detection': [
                            '42 database transactions deadlocked on db-prod-payment ‚Äî payment processing halted',
                            'Deadlock wait timeout after 30s ‚Äî transactions rolling back',
                        ],
                        'diagnosis': [
                            'Root cause: Circular lock dependency ‚Äî Order and Payment tables locked in opposite order',
                            'Evidence: Thread A holds Order lock waiting for Payment; Thread B holds Payment waiting for Order',
                        ],
                        'resolution': [
                            'Killing deadlocked transactions via Azure SQL Management SDK...',
                            'Generating consistent lock ordering fix via GitHub Copilot Agent Mode...',
                            '‚úì 42 deadlocked transactions cleared ‚Äî payment processing resumed',
                            '‚úì PR created: Consistent alphabetical table lock ordering ‚Äî pull/1521',
                        ],
                        'post_mortem': 'Root cause: inconsistent lock ordering in payment flow. Fix: alphabetical lock acquisition order enforced.',
                    },
                    'cache-down': {
                        'detection': [
                            'Redis cache unavailable ‚Äî 100% cache miss rate, API latency 3500ms',
                            '12K users experiencing degraded performance on prod-api',
                        ],
                        'diagnosis': [
                            'Root cause: Redis instance OOM-killed ‚Äî maxmemory-policy set to noeviction',
                            'Evidence: Redis memory at 100% (8GB/8GB), OOM killer log entry at 02:14 UTC',
                        ],
                        'resolution': [
                            'Restarting Redis with updated maxmemory-policy via Azure Cache SDK...',
                            'Generating cache fallback logic via GitHub Copilot Agent Mode...',
                            '‚úì Redis restarted with allkeys-lru policy ‚Äî latency restored to 145ms',
                            '‚úì PR created: Graceful cache fallback to DB on miss ‚Äî pull/1558',
                        ],
                        'post_mortem': 'Root cause: noeviction policy caused OOM. Fix: allkeys-lru policy + cache-aside fallback pattern.',
                    },
                    'slow-query': {
                        'detection': [
                            'Query execution time 35s on db-prod-analytics (baseline: 0.8s)',
                            'Affecting /api/reports endpoint ‚Äî 100% of requests timing out',
                        ],
                        'diagnosis': [
                            'Root cause: Missing index on user_id column in 50M row transactions table',
                            'Evidence: EXPLAIN ANALYZE shows full sequential scan (cost=0..4812847)',
                        ],
                        'resolution': [
                            'Creating index CONCURRENTLY on transactions.user_id via Azure SQL SDK...',
                            'Generating query optimization via GitHub Copilot Agent Mode...',
                            '‚úì Index created ‚Äî query time restored to 0.9s (97% improvement)',
                            '‚úì PR created: Composite index + query rewrite with covering index ‚Äî pull/1601',
                        ],
                        'post_mortem': 'Root cause: missing index on high-cardinality column. Fix: composite index, query planner forced to use it.',
                    },
                    'new-feature-bug': {
                        'detection': [
                            '‚ö†Ô∏è  NOTE: New feature deployment ‚Äî rollback NOT available (no previous slot)',
                            'User Dashboard v2.0 causing NullPointerException ‚Äî 25K failed requests',
                        ],
                        'diagnosis': [
                            'Root cause: NullPointerException in UserProfileComponent.js line 42 ‚Äî missing null guard',
                            'Issue: userData.firstName accessed before null check on userData object',
                        ],
                        'resolution': [
                            '‚ö†Ô∏è  Rollback not possible ‚Äî generating code fix via GitHub Copilot Agent Mode...',
                            'Fix: const displayName = userData?.firstName ? `${userData.firstName} ${userData.lastName}` : "User Profile"',
                            '‚úì Copilot fix generated with 96% code quality score',
                            '‚úì PR created: Null-safe optional chaining throughout UserProfileComponent ‚Äî pull/2847',
                            'Running 847 automated tests...',
                            '‚úì All tests passed ‚Äî 98.2% code coverage maintained',
                        ],
                        'post_mortem': 'Root cause: missing null guard on new user object shape. Fix: optional chaining + default fallback applied.',
                    },
                }

                messages = scenario_details.get(scenario_type, scenario_details['database-spike'])

                duration = scenario['duration']
                mttr = scenario['mttr_seconds']

                def fmt(s):
                    m, sec = divmod(s, 60)
                    return f"{m}m {sec}s" if m else f"{sec}s"

                # ‚îÄ‚îÄ DETECTION (scenario-specific logs, always fast) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                add_log('Detection', f'Scanning resource: {scenario["affected_resource"]}...')
                update_agent_status('detection', 'working')
                time.sleep(1)
                add_log('Detection', f'‚úì Anomaly confirmed: {scenario["title"]}')
                add_log('Detection', f'Severity: {scenario["severity"].upper()} | Resource: {scenario["affected_resource"]}')
                for detail in messages['detection']:
                    add_log('Detection', detail)
                update_agent_status('detection', 'idle', {'incidents_detected': agent_status['detection']['incidents_detected'] + 1})
                update_incident_status(incident['id'], 'diagnosing', int(mttr * 0.1))

                # ‚îÄ‚îÄ DIAGNOSIS (real GitHub Models AI call, sync) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                update_agent_status('diagnosis', 'working')
                diagnosis_result = None

                if _AI_CLIENT:
                    base = _SCENARIO_INCIDENTS.get(scenario_type, _SCENARIO_INCIDENTS['database-spike'])
                    resource = base['resource']
                    anomaly = base['anomalies'][0]
                    prompt = (
                        f"Azure incident: {scenario['title']}\n"
                        f"Resource: {resource['type']} '{resource['name']}'\n"
                        f"Anomaly: {anomaly['metric']} = {anomaly['value']} (threshold {anomaly['threshold']})\n"
                        f"Severity: {scenario['severity']}\n\n"
                        "Respond with ONLY valid JSON:\n"
                        '{"type":"snake_case","description":"one sentence","affected_component":"name",'
                        '"evidence":["point1","point2"]}'
                    )
                    add_log('Diagnosis', f'ü§ñ Calling GitHub Models ({_AI_MODEL}) for root cause analysis...')
                    try:
                        resp = _AI_CLIENT.complete(
                            model=_AI_MODEL,
                            messages=[
                                SystemMessage(content="You are an expert SRE. Respond with ONLY valid JSON, no markdown."),
                                UserMessage(content=prompt),
                            ],
                            temperature=0.2,
                            max_tokens=300,
                        )
                        raw = resp.choices[0].message.content.strip()
                        if raw.startswith("```"):
                            raw = raw.split("```")[1]
                            if raw.startswith("json"):
                                raw = raw[4:]
                        rc = json.loads(raw)
                        conf = 82
                        diagnosis_result = {'root_cause': rc, 'confidence': conf}
                        add_log('Diagnosis', f'‚úì Root cause identified with {conf}% confidence')
                        add_log('Diagnosis', f'  ‚Üí {rc.get("description", "")}')
                        add_log('Diagnosis', f'  Affected: {rc.get("affected_component", "")}')
                        for ev in rc.get('evidence', [])[:2]:
                            add_log('Diagnosis', f'  Evidence: {ev}')
                    except Exception as e:
                        add_log('Diagnosis', f'‚ö†Ô∏è  AI error ({type(e).__name__}) ‚Äî using scenario details')
                        for detail in messages['diagnosis']:
                            add_log('Diagnosis', detail)
                else:
                    time.sleep(2)
                    add_log('Diagnosis', '‚úì Root cause identified with 87% confidence')
                    for detail in messages['diagnosis']:
                        add_log('Diagnosis', detail)

                update_agent_status('diagnosis', 'idle', {'analyses_completed': agent_status['diagnosis']['analyses_completed'] + 1})
                update_incident_status(incident['id'], 'resolving', int(mttr * 0.4))

                # ‚îÄ‚îÄ RESOLUTION (Azure SDK call) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                update_agent_status('resolution', 'working')

                if _REAL_AGENTS and diagnosis_result:
                    add_log('Resolution', '‚öôÔ∏è  Executing automated fix via Azure SDK...')
                    try:
                        import asyncio as _asyncio
                        res_agent = _ResolutionAgent()
                        loop = _asyncio.new_event_loop()
                        try:
                            resolution_result = loop.run_until_complete(res_agent.resolve_incident(diagnosis_result))
                        finally:
                            loop.close()
                        if resolution_result:
                            imm = resolution_result.get('immediate_fix', {})
                            if imm.get('success'):
                                add_log('Resolution', f'‚úì {imm.get("details", imm.get("action", "Fix applied"))}')
                            else:
                                msg = imm.get('message') or imm.get('error', 'No automated fix available')
                                add_log('Resolution', f'‚ÑπÔ∏è  Azure SDK: {msg}')
                                for detail in messages['resolution'][-2:]:
                                    add_log('Resolution', detail)
                            if resolution_result.get('pr_url'):
                                add_log('Resolution', f'‚úì PR created: {resolution_result["pr_url"]}')
                        else:
                            for detail in messages['resolution']:
                                add_log('Resolution', detail)
                    except Exception as e:
                        add_log('Resolution', f'‚ö†Ô∏è  Azure SDK ({type(e).__name__}) ‚Äî using scenario details')
                        for detail in messages['resolution']:
                            add_log('Resolution', detail)
                else:
                    for detail in messages['resolution']:
                        add_log('Resolution', detail)
                        time.sleep(0.5)

                update_agent_status('resolution', 'idle', {'issues_resolved': agent_status['resolution']['issues_resolved'] + 1})
                update_incident_status(incident['id'], 'communicating', int(mttr * 0.8))

                # ‚îÄ‚îÄ COMMUNICATION ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                add_log('Communication', 'Generating post-mortem report...')
                update_agent_status('communication', 'working')
                time.sleep(1)
                add_log('Communication', '‚úì Post-mortem generated and saved to incident knowledge base')
                add_log('Communication', f'Post-mortem: {messages["post_mortem"]}')
                manual_mttr = mttr * 9
                add_log('Communication', f'‚úì Incident resolved in {fmt(mttr)} | ~89% faster than manual MTTR (~{fmt(manual_mttr)})')
                update_agent_status('communication', 'idle', {'notifications_sent': agent_status['communication']['notifications_sent'] + 1})
                update_incident_status(incident['id'], 'resolved', mttr)

                # ‚îÄ‚îÄ METRICS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                _resolved_count += 1
                current_avg = metrics['avg_mttr']
                new_avg = int(current_avg + (mttr - current_avg) / _resolved_count)
                update_metrics({
                    'incidents_this_week': metrics['incidents_this_week'] + 1,
                    'avg_mttr': new_avg,
                    'resolution_rate': min(99, int(85 + (_resolved_count * 0.5))),
                })
            except Exception as e:
                print(f"Error in workflow: {str(e)}")
                add_log('Error', f'Workflow failed: {str(e)}')
                update_incident_status(incident['id'], 'error')
        
        thread = Thread(target=simulate_workflow)
        thread.daemon = True
        thread.start()
        
        return jsonify(incident), 201
    except Exception as e:
        print(f"Error triggering incident: {str(e)}")
        return jsonify({'error': str(e)}), 500


if __name__ == '__main__':
    socketio.run(app, host='0.0.0.0', port=8080, debug=False, use_reloader=False)
